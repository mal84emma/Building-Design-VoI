{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test building load profile scenario reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..') # move to the root directory (from dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scenarioReducer import Fast_forward\n",
    "from utils import scale_profile\n",
    "from prob_models import shape_prior_model, level_prior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up params\n",
    "years = list(range(2012, 2018))\n",
    "ids = [0, 4, 8, 19, 25, 40, 58, 102, 104, 118]\n",
    "\n",
    "data_dir = os.path.join('data','processed')\n",
    "building_file_pattern = 'ly_{id}-{year}.csv'\n",
    "\n",
    "n_buildings = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample vectors of building-years (scenarios)\n",
    "np.random.seed(0)\n",
    "n_samples = 1000\n",
    "scenarios = shape_prior_model(n_buildings, n_samples, ids, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load building-year load profiles once to reduce I/O time\n",
    "load_profiles = {\n",
    "    f'{building_id}-{year}': pd.read_csv(\n",
    "        os.path.join(data_dir, building_file_pattern.format(id=building_id, year=year)),\n",
    "        usecols=['Equipment Electric Power [kWh]']\n",
    "        )['Equipment Electric Power [kWh]'].to_numpy()\\\n",
    "            for building_id, year in itertools.product(ids, years)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scenario_stats(building_scenario_vector, load_profiles_dict):\n",
    "    \"\"\"Compute mean, standard deviation, and peak of aggregate load for a given scenario,\n",
    "    i.e. set of building-year profiles (profiles for each building in scenario).\"\"\"\n",
    "\n",
    "    load_profiles = []\n",
    "\n",
    "    for building_tuple in building_scenario_vector:\n",
    "        if len(building_tuple) == 2:\n",
    "            building_id,year = building_tuple\n",
    "        if len(building_tuple) == 4:\n",
    "            building_id,year = building_tuple[:2]\n",
    "            mean,peak = building_tuple[2:]\n",
    "\n",
    "        load_profile = load_profiles_dict[f'{int(building_id)}-{int(year)}']\n",
    "\n",
    "        if len(building_tuple) == 4:\n",
    "            load_profile = scale_profile(load_profile, mean, peak)\n",
    "\n",
    "        load_profiles.append(load_profile)\n",
    "\n",
    "    aggregate_load = np.sum(load_profiles, axis=0)\n",
    "\n",
    "    return np.mean(aggregate_load), np.std(aggregate_load), np.max(aggregate_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_array(a, invert=False, bounds=None):\n",
    "    assert not (invert and bounds is None), 'bounds must be provided when inverting scaling.'\n",
    "    old_bounds = (a.min(), a.max()) if not invert else (0, 1)\n",
    "    new_bounds = (0, 1) if not invert else bounds\n",
    "    return np.interp(a, old_bounds, new_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_stats = np.array([get_scenario_stats(scenario, load_profiles) for scenario in scenarios])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scenario_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(np.min(scenario_stats[:,0]), np.max(scenario_stats[:,0])),(np.min(scenario_stats[:,1]), np.max(scenario_stats[:,1])),(np.min(scenario_stats[:,2]), np.max(scenario_stats[:,2]))]\n",
    "print(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale scenario stats to range [-1,1] for each exis\n",
    "scaled_scenario_stats = np.array([rescale_array(scenario_stats[:,0]), rescale_array(scenario_stats[:,1]), rescale_array(scenario_stats[:,2])]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform scenario reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.ones(shape=n_samples)/n_samples # uniform probability of scenarios\n",
    "num_reduced_scenarios = 10\n",
    "\n",
    "FFreducer = Fast_forward(scaled_scenario_stats.T, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_scenario_stats, reduced_probs, reduced_indices = FFreducer.reduce(distance=1,n_scenarios=num_reduced_scenarios)\n",
    "# use 1-norm distance metric for reduction\n",
    "reduced_scenario_stats = reduced_scenario_stats.T\n",
    "reduced_scenarios = scenarios[reduced_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_reduced_scenario_stats = np.array([rescale_array(reduced_scenario_stats[:,0], invert=True, bounds=bounds[0]), rescale_array(reduced_scenario_stats[:,1], invert=True, bounds=bounds[1]), rescale_array(reduced_scenario_stats[:,2], invert=True, bounds=bounds[2])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check reduced scenarios have been accessed correctly\n",
    "assert np.isclose(rescaled_reduced_scenario_stats, scenario_stats[reduced_indices]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rescaled_reduced_scenario_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scenarios[reduced_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test modulised version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_scenario_reduction import reduce_load_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_reduced_scenarios, reduced_probs = reduce_load_scenarios(scenarios, load_profiles, num_reduced_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(module_reduced_scenarios)\n",
    "print(reduced_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(module_reduced_scenarios, reduced_scenarios).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BD-VOI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
